{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "focused-charles",
   "metadata": {},
   "source": [
    "# Structured Spark API Examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "northern-still",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SimpleApp\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "drawn-radius",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "studentsdf = spark.read.csv(\"../data/StudentsPerformance.csv\",header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "parallel-treasure",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+\n",
      "|gender|race/ethnicity|parental level of education|       lunch|test preparation course|math score|reading score|writing score|\n",
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+\n",
      "|female|       group B|          bachelor's degree|    standard|                   none|        72|           72|           74|\n",
      "|female|       group C|               some college|    standard|              completed|        69|           90|           88|\n",
      "|female|       group B|            master's degree|    standard|                   none|        90|           95|           93|\n",
      "|  male|       group A|         associate's degree|free/reduced|                   none|        47|           57|           44|\n",
      "|  male|       group C|               some college|    standard|                   none|        76|           78|           75|\n",
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "studentsdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "annoying-detective",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|number|\n",
      "+------+\n",
      "|     0|\n",
      "|     1|\n",
      "|     2|\n",
      "|     3|\n",
      "|     4|\n",
      "|     5|\n",
      "|     6|\n",
      "|     7|\n",
      "|     8|\n",
      "|     9|\n",
      "+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.range(100).toDF(\"number\")\n",
    "df.select(df[\"number\"]+10)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "forward-elizabeth",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|number|\n",
      "+------+\n",
      "|     6|\n",
      "|     7|\n",
      "|     8|\n",
      "|     9|\n",
      "|    10|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['number'] > 5).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "recognized-father",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gender: string (nullable = true)\n",
      " |-- race/ethnicity: string (nullable = true)\n",
      " |-- parental level of education: string (nullable = true)\n",
      " |-- lunch: string (nullable = true)\n",
      " |-- test preparation course: string (nullable = true)\n",
      " |-- math score: string (nullable = true)\n",
      " |-- reading score: string (nullable = true)\n",
      " |-- writing score: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "studentsdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "starting-olive",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Infer the schema, and register the DataFrame as a table.  WHERE cast('math score' as int) >= 90\"\n",
    "studentsdf.createOrReplaceTempView(\"studentsql\")\n",
    "maths = spark.sql(\"SELECT cast('math score' as int) as age FROM studentsql WHERE cast('math score' as int) >= 90\" )\n",
    "maths.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "transparent-seattle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(gender,StringType,true),StructField(race/ethnicity,StringType,true),StructField(parental level of education,StringType,true),StructField(lunch,StringType,true),StructField(test preparation course,StringType,true),StructField(math score,StringType,true),StructField(reading score,StringType,true),StructField(writing score,StringType,true)))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studentsdf.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "elect-continent",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gender: string (nullable = true)\n",
      " |-- race/ethnicity: string (nullable = true)\n",
      " |-- parental level of education: long (nullable = true)\n",
      " |-- lunch: string (nullable = true)\n",
      " |-- test preparation course: string (nullable = true)\n",
      " |-- math score: long (nullable = true)\n",
      " |-- reading score: long (nullable = true)\n",
      " |-- writing score: long (nullable = true)\n",
      "\n",
      "+------+--------------+------------+-----------------------+----------+-------------+-------------+\n",
      "|gender|race/ethnicity|       lunch|test preparation course|math score|reading score|writing score|\n",
      "+------+--------------+------------+-----------------------+----------+-------------+-------------+\n",
      "|gender|race/ethnicity|       lunch|   test preparation ...|      null|         null|         null|\n",
      "|female|       group B|    standard|                   none|        72|           72|           74|\n",
      "|female|       group C|    standard|              completed|        69|           90|           88|\n",
      "|female|       group B|    standard|                   none|        90|           95|           93|\n",
      "|  male|       group A|free/reduced|                   none|        47|           57|           44|\n",
      "+------+--------------+------------+-----------------------+----------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "\n",
    "mySchema = StructType([\n",
    "StructField(\"gender\", StringType(), True),\n",
    "StructField(\"race/ethnicity\", StringType(), True),\n",
    "StructField(\"parental level of education\", LongType(), False),\n",
    "StructField(\"lunch\", StringType(), True), \n",
    "StructField(\"test preparation course\", StringType(), True),\n",
    "StructField(\"math score\", LongType(), True), \n",
    "StructField(\"reading score\", LongType(), True), \n",
    "StructField(\"writing score\", LongType(), True)\n",
    "])\n",
    "studentsdfmyschema = spark.read.format(\"csv\").schema(mySchema).load(\"../data/StudentsPerformance.csv\")\n",
    "studentsdfmyschema.printSchema()\n",
    "studentsdfmyschema.drop('parental level of education').show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "finished-doubt",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender',\n",
       " 'race/ethnicity',\n",
       " 'parental level of education',\n",
       " 'lunch',\n",
       " 'test preparation course',\n",
       " 'math score',\n",
       " 'reading score',\n",
       " 'writing score']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studentsdfmyschema.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dated-subject",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---+\n",
      "|first_name|last_name|age|\n",
      "+----------+---------+---+\n",
      "|      siva|   selvam| 30|\n",
      "+----------+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "myManualSchema = StructType([\n",
    "StructField(\"first_name\", StringType(), True),\n",
    "StructField(\"last_name\", StringType(), True),\n",
    "StructField(\"age\", LongType(), False)\n",
    "])\n",
    "myRow = Row(\"siva\", \"selvam\", 30)\n",
    "myDf = spark.createDataFrame([myRow], myManualSchema)\n",
    "myDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "diverse-input",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|count(math score)|\n",
      "+-----------------+\n",
      "|             1001|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "studentsdfmyschema.selectExpr(\"count('math score')\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "plain-operations",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---------------------------+-----+-----------------------+----------+-------------+-------------+\n",
      "|gender|race/ethnicity|parental level of education|lunch|test preparation course|math score|reading score|writing score|\n",
      "+------+--------------+---------------------------+-----+-----------------------+----------+-------------+-------------+\n",
      "+------+--------------+---------------------------+-----+-----------------------+----------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "studentsdfmyschema.where(col(\"math score\") < 90).show()\n",
    "#studentsdfmyschema = studentsdfmyschema.filter(\" <> \")\n",
    "#studentsdfmyschema.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "operational-jurisdiction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     482|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnt = spark.sql(\"SELECT count(*) FROM studentsql where gender='male'\" )\n",
    "cnt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "korean-johnston",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---------------------------+-----+-----------------------+----------+-------------+-------------+\n",
      "|gender|race/ethnicity|parental level of education|lunch|test preparation course|math score|reading score|writing score|\n",
      "+------+--------------+---------------------------+-----+-----------------------+----------+-------------+-------------+\n",
      "+------+--------------+---------------------------+-----+-----------------------+----------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "studentsdfmyschema.sort(\"gender\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "laughing-disorder",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+-----------------+--------------------+-------------+-----------------+------------+------+---------+--------------------+--------------------+\n",
      "|show_id|   type|title|         director|                cast|      country|       date_added|release_year|rating| duration|           listed_in|         description|\n",
      "+-------+-------+-----+-----------------+--------------------+-------------+-----------------+------------+------+---------+--------------------+--------------------+\n",
      "|     s1|TV Show|   3%|             null|João Miguel, Bian...|       Brazil|  August 14, 2020|        2020| TV-MA|4 Seasons|International TV ...|In a future where...|\n",
      "|     s2|  Movie| 7:19|Jorge Michel Grau|Demián Bichir, Hé...|       Mexico|December 23, 2016|        2016| TV-MA|   93 min|Dramas, Internati...|After a devastati...|\n",
      "|     s3|  Movie|23:59|     Gilbert Chan|Tedd Chan, Stella...|    Singapore|December 20, 2018|        2011|     R|   78 min|Horror Movies, In...|When an army recr...|\n",
      "|     s4|  Movie|    9|      Shane Acker|Elijah Wood, John...|United States|November 16, 2017|        2009| PG-13|   80 min|Action & Adventur...|In a postapocalyp...|\n",
      "|     s5|  Movie|   21|   Robert Luketic|Jim Sturgess, Kev...|United States|  January 1, 2020|        2008| PG-13|  123 min|              Dramas|A brilliant group...|\n",
      "+-------+-------+-----+-----------------+--------------------+-------------+-----------------+------------+------+---------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "netflix = spark.read.csv(\"../data/netflix_titles.csv\",header='true')\n",
    "netflix.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fleet-fireplace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- show_id: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- cast: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- date_added: string (nullable = true)\n",
      " |-- release_year: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- listed_in: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "netflix.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "happy-domestic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------------+\n",
      "|               title|rating|release_year|\n",
      "+--------------------+------+------------+\n",
      "|                  3%| TV-MA|        2020|\n",
      "|​SAINT SEIYA: Kni...| TV-14|        2020|\n",
      "|            (Un)Well| TV-MA|        2020|\n",
      "|              #Alive| TV-MA|        2020|\n",
      "|            #blackAF| TV-MA|        2020|\n",
      "+--------------------+------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "netflixview= netflix.createOrReplaceTempView(\"netflixview\")\n",
    "spark.sql(\"select title, rating, release_year from netflixview where release_year = 2020\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "proprietary-relations",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "activated-concentration",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix.repartition(3)\n",
    "netflix.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "failing-fellowship",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+-----------+------------+\n",
      "|              title|        director|    country|release_year|\n",
      "+-------------------+----------------+-----------+------------+\n",
      "|             #Alive|          Cho Il|South Korea|        2020|\n",
      "|   #cats_the_mewvie|Michael Margolis|     Canada|        2020|\n",
      "|#FriendButMarried 2|   Rako Prijanto|  Indonesia|        2020|\n",
      "|            Òlòtūré|   Kenneth Gyang|    Nigeria|        2020|\n",
      "|         100% Halal|   Jastis Arimba|  Indonesia|        2020|\n",
      "+-------------------+----------------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "netflix.where(col(\"release_year\")==2020).where(col(\"director\").isNotNull()).select(\"title\",\"director\",\"country\",\"release_year\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "excessive-helmet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+------------+\n",
      "|        director|    country|release_year|\n",
      "+----------------+-----------+------------+\n",
      "|          Cho Il|South Korea|        2020|\n",
      "|Michael Margolis|     Canada|        2020|\n",
      "|   Rako Prijanto|  Indonesia|        2020|\n",
      "|   Kenneth Gyang|    Nigeria|        2020|\n",
      "|   Jastis Arimba|  Indonesia|        2020|\n",
      "+----------------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import instr\n",
    "releaseYearFilter = col(\"release_year\") == 2020\n",
    "directorFilter = instr(col(\"director\"), \"Kenneth\") >= 1\n",
    "\n",
    "netflix\\\n",
    ".where(col(\"director\").isNotNull())\\\n",
    ".withColumn(\"directYear\", (releaseYearFilter | directorFilter))\\\n",
    ".where(\"directYear\")\\\n",
    ".select(\"director\", \"country\",\"release_year\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "disabled-patio",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|round(2.5, 0)|bround(2.5, 0)|\n",
      "+-------------+--------------+\n",
      "|          3.0|           2.0|\n",
      "|          3.0|           2.0|\n",
      "+-------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, round, bround\n",
    "netflix.select(round(lit(\"2.5\")), bround(lit(\"2.5\"))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "visible-brook",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|round(2.5, 0)|bround(2.5, 0)|\n",
      "+-------------+--------------+\n",
      "|          3.0|           2.0|\n",
      "|          3.0|           2.0|\n",
      "+-------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, round, bround\n",
    "netflix.select(round(lit(\"2.5\")), bround(lit(\"2.5\"))).show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "animated-blackjack",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------------+---------------------------------+--------------------+--------------------+----------------+---------------+------------------+-----------------+-------------+---------------+--------------------+\n",
      "|summary|             show_id|         type|                            title|            director|                cast|         country|     date_added|      release_year|           rating|     duration|      listed_in|         description|\n",
      "+-------+--------------------+-------------+---------------------------------+--------------------+--------------------+----------------+---------------+------------------+-----------------+-------------+---------------+--------------------+\n",
      "|  count|                7789|         7788|                             7787|                5398|                7070|            7280|           7777|              7787|             7780|         7787|           7786|                7786|\n",
      "|   mean|                null|         null|               1084.7272727272727|                null|                null|          1944.0|           null|2013.9396551724137|          2015.75|       1994.0|           null|  2014.6666666666667|\n",
      "| stddev|                null|         null|               1096.7795668145072|                null|                null|            null|           null| 8.724664209815797|6.701989754294367|         null|           null|   4.509249752822894|\n",
      "|    min| and probably will.\"|        Movie|             \"Behind \"\"The Cov...|\"Sam \"\"Blitz\"\" Ba...|\"Black Deniro, By...| Ama K. Abebrese| April 15, 2018|    Francis Weddey|    Adriane Lenox| Alan Cumming| Eden Marryshow|      Alicia Sánchez|\n",
      "|    max|                s999|William Wyler|최강전사 미니특공대 : 영웅의 탄생|        Şenol Sönmez|Ṣọpẹ́ Dìrísù, Wun...|        Zimbabwe|  United States|     United States|               UR|United States|  United States|Zoe Walker leaves...|\n",
      "+-------+--------------------+-------------+---------------------------------+--------------------+--------------------+----------------+---------------+------------------+-----------------+-------------+---------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "netflix.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-occasion",
   "metadata": {},
   "source": [
    "## String Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "perfect-daniel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|initcap(description)|\n",
      "+--------------------+\n",
      "|In A Future Where...|\n",
      "|After A Devastati...|\n",
      "|When An Army Recr...|\n",
      "|In A Postapocalyp...|\n",
      "|A Brilliant Group...|\n",
      "|A Genetics Profes...|\n",
      "+--------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import initcap,upper,lower\n",
    "netflix.select(initcap(col(\"description\"))).show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "operating-affairs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|         description|  upper(description)|  lower(description)|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|In a future where...|IN A FUTURE WHERE...|in a future where...|\n",
      "|After a devastati...|AFTER A DEVASTATI...|after a devastati...|\n",
      "|When an army recr...|WHEN AN ARMY RECR...|when an army recr...|\n",
      "|In a postapocalyp...|IN A POSTAPOCALYP...|in a postapocalyp...|\n",
      "|A brilliant group...|A BRILLIANT GROUP...|a brilliant group...|\n",
      "|A genetics profes...|A GENETICS PROFES...|a genetics profes...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "netflix.select(col(\"description\"), upper(col(\"description\")),lower(col(\"description\"))).show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "revolutionary-burton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-----+---+----------+\n",
      "| ltrim| rtrim| trim| lp|        rp|\n",
      "+------+------+-----+---+----------+\n",
      "|HELLO | HELLO|HELLO|HEL|HELLO     |\n",
      "|HELLO | HELLO|HELLO|HEL|HELLO     |\n",
      "+------+------+-----+---+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, ltrim, rtrim, rpad, lpad, trim\n",
    "df.select(\n",
    "ltrim(lit(\" HELLO \")).alias(\"ltrim\"),\n",
    "rtrim(lit(\" HELLO \")).alias(\"rtrim\"),\n",
    "trim(lit(\" HELLO \")).alias(\"trim\"),\n",
    "lpad(lit(\"HELLO\"), 3, \" \").alias(\"lp\"),\n",
    "rpad(lit(\"HELLO\"), 10, \" \").alias(\"rp\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "electronic-punishment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|     release_year|total_movie_count|\n",
      "+-----------------+-----------------+\n",
      "|             2020|              867|\n",
      "|             2008|              125|\n",
      "|             2019|              992|\n",
      "|             1997|               30|\n",
      "|             2015|              540|\n",
      "|             2012|              219|\n",
      "|             2000|               34|\n",
      "|             2003|               49|\n",
      "|             1980|                9|\n",
      "|             1991|               17|\n",
      "|             1992|               18|\n",
      "|             2021|               30|\n",
      "|             1967|                5|\n",
      "|             1968|                5|\n",
      "| Marquell Manning|                1|\n",
      "|             1987|                7|\n",
      "| Kristen Johnston|                1|\n",
      "|             1942|                2|\n",
      "|             1963|                2|\n",
      "|             2017|             1010|\n",
      "+-----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------------+\n",
      "|total_movies|\n",
      "+------------+\n",
      "|        7789|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxSql = spark.sql(\"\"\"\n",
    "SELECT  release_year,count(*) as total_movie_count\n",
    "FROM netflixview\n",
    "GROUP BY release_year\n",
    "\"\"\")\n",
    "maxSql.show()\n",
    "\n",
    "totSql = spark.sql(\"\"\"SELECT  count(*) as total_movies FROM netflixview\"\"\")\n",
    "totSql.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "julian-directive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- today: date (nullable = false)\n",
      " |-- now: timestamp (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_date, current_timestamp\n",
    "\n",
    "dateDF = spark.range(10)\\\n",
    ".withColumn(\"today\", current_date())\\\n",
    ".withColumn(\"now\", current_timestamp())\n",
    "\n",
    "dateDF.createOrReplaceTempView(\"dateTable\")\n",
    "dateDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "trying-tolerance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+\n",
      "| id|     today|                 now|\n",
      "+---+----------+--------------------+\n",
      "|  0|2021-05-14|2021-05-14 19:53:...|\n",
      "|  1|2021-05-14|2021-05-14 19:53:...|\n",
      "|  2|2021-05-14|2021-05-14 19:53:...|\n",
      "|  3|2021-05-14|2021-05-14 19:53:...|\n",
      "|  4|2021-05-14|2021-05-14 19:53:...|\n",
      "|  5|2021-05-14|2021-05-14 19:53:...|\n",
      "|  6|2021-05-14|2021-05-14 19:53:...|\n",
      "|  7|2021-05-14|2021-05-14 19:53:...|\n",
      "|  8|2021-05-14|2021-05-14 19:53:...|\n",
      "|  9|2021-05-14|2021-05-14 19:53:...|\n",
      "+---+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "settled-boards",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|coalesce(show_id)|\n",
      "+-----------------+\n",
      "|               s1|\n",
      "|               s2|\n",
      "|               s3|\n",
      "|               s4|\n",
      "|               s5|\n",
      "|               s6|\n",
      "|               s7|\n",
      "|               s8|\n",
      "|               s9|\n",
      "|              s10|\n",
      "|              s11|\n",
      "|              s12|\n",
      "|              s13|\n",
      "|              s14|\n",
      "|              s15|\n",
      "|              s16|\n",
      "|              s17|\n",
      "|              s18|\n",
      "|              s19|\n",
      "|              s20|\n",
      "+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import coalesce\n",
    "netflix.select(coalesce(col(\"show_id\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "expired-settlement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first  second\n",
       "0      0      50\n",
       "1      1      51\n",
       "2      2      52\n",
       "3      3      53\n",
       "4      4      54"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\"first\":range(200), \"second\":range(50,250)})\n",
    "\n",
    "sparkDF = spark.createDataFrame(df)\n",
    "\n",
    "\n",
    "newPDF = sparkDF.toPandas()\n",
    "newPDF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "innocent-decimal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+-----------------+--------------------+-------------+-----------------+------------+------+---------+--------------------+--------------------+\n",
      "|show_id|   type|title|         director|                cast|      country|       date_added|release_year|rating| duration|           listed_in|         description|\n",
      "+-------+-------+-----+-----------------+--------------------+-------------+-----------------+------------+------+---------+--------------------+--------------------+\n",
      "|     s1|TV Show|   3%|             null|João Miguel, Bian...|       Brazil|  August 14, 2020|        2020| TV-MA|4 Seasons|International TV ...|In a future where...|\n",
      "|     s2|  Movie| 7:19|Jorge Michel Grau|Demián Bichir, Hé...|       Mexico|December 23, 2016|        2016| TV-MA|   93 min|Dramas, Internati...|After a devastati...|\n",
      "|     s3|  Movie|23:59|     Gilbert Chan|Tedd Chan, Stella...|    Singapore|December 20, 2018|        2011|     R|   78 min|Horror Movies, In...|When an army recr...|\n",
      "|     s4|  Movie|    9|      Shane Acker|Elijah Wood, John...|United States|November 16, 2017|        2009| PG-13|   80 min|Action & Adventur...|In a postapocalyp...|\n",
      "|     s5|  Movie|   21|   Robert Luketic|Jim Sturgess, Kev...|United States|  January 1, 2020|        2008| PG-13|  123 min|              Dramas|A brilliant group...|\n",
      "|     s6|TV Show|   46|      Serdar Akar|Erdal Beşikçioğlu...|       Turkey|     July 1, 2017|        2016| TV-MA| 1 Season|International TV ...|A genetics profes...|\n",
      "|     s7|  Movie|  122|  Yasir Al Yasiri|Amina Khalil, Ahm...|        Egypt|     June 1, 2020|        2019| TV-MA|   95 min|Horror Movies, In...|After an awful ac...|\n",
      "|     s8|  Movie|  187|   Kevin Reynolds|Samuel L. Jackson...|United States| November 1, 2019|        1997|     R|  119 min|              Dramas|After one of his ...|\n",
      "|     s9|  Movie|  706|    Shravan Kumar|Divya Dutta, Atul...|        India|    April 1, 2019|        2019| TV-14|  118 min|Horror Movies, In...|When a doctor goe...|\n",
      "|    s10|  Movie| 1920|     Vikram Bhatt|Rajneesh Duggal, ...|        India|December 15, 2017|        2008| TV-MA|  143 min|Horror Movies, In...|An architect and ...|\n",
      "+-------+-------+-----+-----------------+--------------------+-------------+-----------------+------------+------+---------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#netflix.show(10)\n",
    "netflix.na.drop(\"any\")\n",
    "netflix.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "psychological-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import struct\n",
    "complexDF = netflix.select(struct(\"Description\", \"title\").alias(\"complex\"))\n",
    "complexDF.createOrReplaceTempView(\"complexDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "wrapped-association",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             complex|\n",
      "+--------------------+\n",
      "|{In a future wher...|\n",
      "|{After a devastat...|\n",
      "|{When an army rec...|\n",
      "|{In a postapocaly...|\n",
      "|{A brilliant grou...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from complexDF\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "olive-seating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|split(Description,  , -1)|\n",
      "+-------------------------+\n",
      "|     [In, a, future, w...|\n",
      "|     [After, a, devast...|\n",
      "+-------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split\n",
    "netflix.select(split(col(\"Description\"), \" \")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "transparent-translation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|  from_json(newJSON)|             newJSON|\n",
      "+--------------------+--------------------+\n",
      "|{s1, In a future ...|{\"show_id\":\"s1\",\"...|\n",
      "|{s2, After a deva...|{\"show_id\":\"s2\",\"...|\n",
      "|{s3, When an army...|{\"show_id\":\"s3\",\"...|\n",
      "|{s4, In a postapo...|{\"show_id\":\"s4\",\"...|\n",
      "|{s5, A brilliant ...|{\"show_id\":\"s5\",\"...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import from_json,to_json\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "parseSchema = StructType((\n",
    "StructField(\"show_id\",StringType(),True),\n",
    "StructField(\"Description\",StringType(),True)))\n",
    "\n",
    "netflix.selectExpr(\"(show_id, Description) as myStruct\")\\\n",
    ".select(to_json(col(\"myStruct\")).alias(\"newJSON\"))\\\n",
    ".select(from_json(col(\"newJSON\"), parseSchema), col(\"newJSON\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "australian-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "valued-record",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s1</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>3%</td>\n",
       "      <td>None</td>\n",
       "      <td>João Miguel, Bianca Comparato, Michel Gomes, R...</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>August 14, 2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>4 Seasons</td>\n",
       "      <td>International TV Shows, TV Dramas, TV Sci-Fi &amp;...</td>\n",
       "      <td>In a future where the elite inhabit an island ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s2</td>\n",
       "      <td>Movie</td>\n",
       "      <td>7:19</td>\n",
       "      <td>Jorge Michel Grau</td>\n",
       "      <td>Demián Bichir, Héctor Bonilla, Oscar Serrano, ...</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>December 23, 2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>93 min</td>\n",
       "      <td>Dramas, International Movies</td>\n",
       "      <td>After a devastating earthquake hits Mexico Cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3</td>\n",
       "      <td>Movie</td>\n",
       "      <td>23:59</td>\n",
       "      <td>Gilbert Chan</td>\n",
       "      <td>Tedd Chan, Stella Chung, Henley Hii, Lawrence ...</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>December 20, 2018</td>\n",
       "      <td>2011</td>\n",
       "      <td>R</td>\n",
       "      <td>78 min</td>\n",
       "      <td>Horror Movies, International Movies</td>\n",
       "      <td>When an army recruit is found dead, his fellow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s4</td>\n",
       "      <td>Movie</td>\n",
       "      <td>9</td>\n",
       "      <td>Shane Acker</td>\n",
       "      <td>Elijah Wood, John C. Reilly, Jennifer Connelly...</td>\n",
       "      <td>United States</td>\n",
       "      <td>November 16, 2017</td>\n",
       "      <td>2009</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>80 min</td>\n",
       "      <td>Action &amp; Adventure, Independent Movies, Sci-Fi...</td>\n",
       "      <td>In a postapocalyptic world, rag-doll robots hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s5</td>\n",
       "      <td>Movie</td>\n",
       "      <td>21</td>\n",
       "      <td>Robert Luketic</td>\n",
       "      <td>Jim Sturgess, Kevin Spacey, Kate Bosworth, Aar...</td>\n",
       "      <td>United States</td>\n",
       "      <td>January 1, 2020</td>\n",
       "      <td>2008</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>123 min</td>\n",
       "      <td>Dramas</td>\n",
       "      <td>A brilliant group of students become card-coun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  show_id     type  title           director                                               cast        country         date_added release_year rating   duration                                          listed_in                                        description\n",
       "0      s1  TV Show     3%               None  João Miguel, Bianca Comparato, Michel Gomes, R...         Brazil    August 14, 2020         2020  TV-MA  4 Seasons  International TV Shows, TV Dramas, TV Sci-Fi &...  In a future where the elite inhabit an island ...\n",
       "1      s2    Movie   7:19  Jorge Michel Grau  Demián Bichir, Héctor Bonilla, Oscar Serrano, ...         Mexico  December 23, 2016         2016  TV-MA     93 min                       Dramas, International Movies  After a devastating earthquake hits Mexico Cit...\n",
       "2      s3    Movie  23:59       Gilbert Chan  Tedd Chan, Stella Chung, Henley Hii, Lawrence ...      Singapore  December 20, 2018         2011      R     78 min                Horror Movies, International Movies  When an army recruit is found dead, his fellow...\n",
       "3      s4    Movie      9        Shane Acker  Elijah Wood, John C. Reilly, Jennifer Connelly...  United States  November 16, 2017         2009  PG-13     80 min  Action & Adventure, Independent Movies, Sci-Fi...  In a postapocalyptic world, rag-doll robots hi...\n",
       "4      s5    Movie     21     Robert Luketic  Jim Sturgess, Kevin Spacey, Kate Bosworth, Aar...  United States    January 1, 2020         2008  PG-13    123 min                                             Dramas  A brilliant group of students become card-coun..."
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-insurance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
